<script setup>
</script>

<template>
    <!-- Special Sponsored Meeting -->
    <div class="section">
        <h3 class="text-3xl font-bold flex flex-row gap-3 mb-5">
            Workshop @WCCI 2026 From Algorithms to Accountability: Exploring AI Law and Ethics in Practice
        </h3>
        <p>
            Again, this year, we will complement our Special Session on 'AI, Law and Regulation' efforts with <b>an expert workshop on cutting-edge topics of ethics and law in AI</b>.<br/>
            <br/>
        </p>
        <img src="/maastricht2.png" alt="From Algorithms to Accountability: Exploring AI Law and Ethics in Practice."/>
        <p>
            This year's special initiative is <b>jointly sponsored by the IEEE CIS Technical Committee on Ethical, Legal, 
            Social, Environmental, and Human Dimensions of AI/CI (SHIELD) and the INNS AI Law and Regulation
            (ALR) Section</b>.
        </p>
        <p>
            It features a synergistic collaboration across disciplinary boundaries of legal, ethical, and technical
            communities around one table. The effective governance and responsible adoption of AI in high-stakes
            contexts requires collaborative frameworks that cut across disciplines, sectors, and geographies.
            This theme explores how academia, industry, governments, and civil society can co-create standards,
            share responsibility, and align incentives in the development and oversight of AI systems.
        </p>
        <p>
            By examining <b>case studies and emerging best practices</b>, the session will surface opportunities and barriers
            for building sustainable, trust-based collaborations that ensure both technical robustness and societal
            legitimacy.
        </p>
        <p>
            <b>Who is this workshop for?</b>
        </p>
        <p>
            <b>
                Innovators and practitioners from both public and private sectors who are interested in translational,
                cutting-edge research related to all facets of computational intelligence (CI) and AI theory and
                applications.
            </b>
        </p>
        <p>
            It will present diverse perspectives and equip participants with state-of-the-art frameworks to address
            ongoing ethical and regulatory challenges in practice, as AI policies and regulations evolve rapidly
            worldwide.
        </p>
        <p>
            The workshop will encompass <b>four thematic sessions</b>, each combining provocation, panel exchange,
            and participatory fire-side chats.
        </p>
        <p>
            What's the aim?
        </p>
        <p>
            To foster interdisciplinary, cross-sectoral collaboration in critical areas such as:
            <ul>
                <li>AI literacy in high-stakes applications; socio-technical,</li>
                <li>Translational insights in explainability and transparency;</li>
                <li>Participatory, people-powered AI; and</li>
                <li>Industry Case Studies</li>
            </ul>
        </p>
        <p>
            <b>
                Attend to hear from a range of experts on the current state of play! We adopt a
                translational lens in AI ethics to move from principles to (best) practice, integrating
                technical societies with socio-legal and ethical perspectives.
            </b>
        </p>
        <p>
            Themes with socio-legal considerations and technical contextualisation:
            <ol>
                <li>
                    <b>Navigating Trust through AI Literacy in High-Impact Sectors: Healthcare/Medicine, Finance, and Education</b>
                    <br />Consider what AI literacy is now, and what it should be/mean? Explore context in relation to AI Literacy and what actually do people really want to know?
                </li>
                <li>
                    <b>Socio-Technical Translational Insights on Explainability and Transparency</b>
                    <br />Consider what XAI/ Explainability/ Understandability is now, and what it should be
                </li>
                <li>
                    <b>Participatory AI: People-Powered AI</b>
                    <br />Bridging the gap in Participatory AI practice with citizens  
                </li>
                <li>
                    <b>Industry Case Studies: Responding to and Moving beyond Compliance</b>
                    <br />Certification, documentation, governance structures and risk assessments
                </li>
            </ol>
        </p>
        <p>
            <b>INNS ALR Section:</b>
            <ul>
                <li>
                    <b>Asim Roy</b> (Arizona State University, Chair), Asim.Roy@asu.edu, bio: Asim Roy is
                    a Professor of Information Systems at Arizona State University. Currently, he chairs
                    the INNS Section on Explainable AI (XAI) and co-chairs the INNS Section on AI,
                    Law, and Regulation (ALR).
                </li>
                <li>
                    <b>Amanda Horzyk</b> (University of Edinburgh, Coordinator), A.M.Horzyk@sms.ed.ac.uk,
                    bio: Amanda Horzyk is the AI Law and Regulation INNS Section Coordinator, Founder of
                    the ALR Pioneers Group. Doctoral researcher in Designing Responsible Natural Language
                    Processing at the University of Edinburgh's Futures Institute. Specialised in Internet
                    and AI law, policy, and translational tech ethics. Actively serves in expert working
                    groups at AI4People,Centre for Digital and AI Policy, Geneva-based AI policy convenings.
                </li>
                <li>
                    <b>Maja Nišević</b> (KU Leuven, Member), maja.nisevic@kuleuven.be<br />
                    She is a postdoctoral researcher at the Centre for IT & IP Law (CiTiP) at KU Leuven,
                    where she also serves on the management board and supervises MA and PhD students.
                    Her research focuses on the legal and ethical governance of emerging technologies,
                    including AI, data protection, profiling and big data, cybersecurity, and liability.
                </li>
            </ul>
        </p>
        <p>
            <b>IEEE CIS SHIELD:</b>
            <ul>
                <li>
                    <b>Tayo Obafemi-Ajayi</b> (Missouri State University, 2025 SHIELD Technical Committee Chair),
                    TayoObafemiAjayi@MissouriState.edu, bio: Tayo Obafemi-Ajayi is an associate professor of
                    Electrical Engineering (Guy Mace Professor of Engineering) at Missouri State University
                    (MSU) in the Engineering Program. As the faculty director of the Computational Learning
                    Systems lab, her research focus is on developing explainable and ethical machine
                    learning/AI algorithms for broad utility in biomedical applications including health
                    informatics, deep learning, multi-modal data analysis. She received the MSU Atwood Excellence
                    in Research and Teaching award 2924 and Board of Governor's Faculty Excellence award 2025.
                    She served as a Technical Representative on the Administrative committee of IEEE Engineering
                    Medicine and Biology Society (EMBS) 2023-2025.
                </li>
                <li>
                    <b>Keeley Crockett</b> (Manchester Metropolitan University, IEEE CIS AI Ethics Education and
                    Awareness (AEEA) Taskforce Chair), K.Crockett@mmu.ac.uk, bio: Keeley Crockett is a Professor
                    of Computational Intelligence at Manchester Metropolitan University with over 27 years of
                    experience in ethical and responsible AI. She plays a leading role in shaping UK AI policy and
                    public engagement, serving on national advisory boards and championing inclusive, community-driven
                    approaches to AI development.
                </li>
                <li>
                    <b>Chiara Gallese</b> (University of Tilburg, IEEE CIS SHIELD Member, IEEE CIS BBTC
                    Vice-President), C.Gallese@tilburguniversity.edu, bio: Chiara Gallese is a Researcher at the
                    Tilburg Institute for Law, Technology, and Society and Member of the EU GPAI Code of Practice
                    Working Groups. She was awarded a Marie Sklodowska Curie Fellowship in 2023. Her research is
                    focused on AI Law, Data Ethics, and ML Fairness. 
                </li>
            </ul>
        </p>
    </div>
</template>

<style scoped></style>